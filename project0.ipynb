{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "graphic-bones",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.bag as db"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interested-london",
   "metadata": {},
   "source": [
    "Helper function that displays all the functions that can be invoked on an object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "parallel-netherlands",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_object_method(obj):\n",
    "    object_methods = [method_name for method_name in dir(obj)\n",
    "                  if callable(getattr(obj, method_name))]\n",
    "    print(object_methods)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "endless-illness",
   "metadata": {},
   "source": [
    "Takes an array of lists and filename as input and creates a json file from the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "false-start",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def create_json_file(data, filename):\n",
    "    json_object = dict(data)\n",
    "    json_string = json.dumps(json_object)\n",
    "    open(\"output/%s\" % filename, \"w\").write(json_string)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "joined-combining",
   "metadata": {},
   "source": [
    "Computes the top K words from the bag of words for each of the subproject."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "athletic-wallpaper",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_top_k(words, k=40):\n",
    "    word_frequencies = words.frequencies()\n",
    "    top40_words = word_frequencies.topk(k, key=1)\n",
    "    word_counts = top40_words.compute()\n",
    "    print(word_counts)\n",
    "    return word_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "immediate-pattern",
   "metadata": {},
   "source": [
    "## Subproject 1\n",
    "### Top 40 words across all files\n",
    "- Find top 40 words\n",
    "- No need to filter out stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "banner-tracker",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "booklist = [\n",
    "    \"handout/data/pg36.txt\",\n",
    "    \"handout/data/pg3207.txt\",\n",
    "    \"handout/data/4300-0.txt\",\n",
    "    \"handout/data/pg19033.txt\",\n",
    "    \"handout/data/pg1497.txt\",\n",
    "    \"handout/data/pg42671.txt\",\n",
    "    \"handout/data/pg514.txt\",\n",
    "    \"handout/data/pg6130.txt\"\n",
    "]\n",
    "word_bag = db.read_text(booklist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "julian-guidance",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lowercase_words(word_bag):\n",
    "    stripped_words = word_bag.str.strip()\n",
    "    split_words = stripped_words.str.split(\" \")\n",
    "    word_array = split_words.flatten().filter(lambda x: x!= \"\")\n",
    "    return word_array.map(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "adopted-entity",
   "metadata": {},
   "outputs": [],
   "source": [
    "lowercase_words = get_lowercase_words(word_bag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "vital-herald",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 78837), ('and', 45168), ('of', 44739), ('to', 33436), ('a', 24234), ('in', 22126), ('that', 14818), ('he', 13019), ('is', 12918), ('his', 12270), ('i', 11044), ('with', 10296), ('for', 10036), ('as', 9639), ('be', 8834), ('was', 8787), ('not', 8141), ('it', 8123), ('but', 7856), ('by', 7701), ('or', 7407), ('her', 7403), ('they', 6735), ('which', 6517), ('you', 6354), ('on', 6214), ('from', 5811), ('at', 5695), ('are', 5590), ('she', 5458), ('all', 5437), ('their', 5285), ('have', 5146), ('had', 4647), ('this', 4090), ('my', 3841), ('so', 3710), ('we', 3629), ('no', 3620), ('if', 3571)]\n"
     ]
    }
   ],
   "source": [
    "top_40 = compute_top_k(lowercase_words, k=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "after-injury",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_json_file(top_40, \"sp1.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unsigned-isolation",
   "metadata": {},
   "source": [
    "## Subproject 2\n",
    "### Top 40 filtered words\n",
    "- Find top 40 words\n",
    "- Filter out the stopwords from the handout file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "accessory-donor",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filtered_words(words):\n",
    "    stopwords = open(\"handout/data/stopwords.txt\", \"r\").read().split(\"\\n\")\n",
    "    return words.filter(lambda x: x not in stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "rising-allergy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('i', 11044), ('not', 8141), ('you', 6354), ('have', 5146), ('no', 3620), ('one', 3498), ('like', 2253), ('more', 2087), ('out', 2021), ('up', 1831), ('man', 1783), ('now', 1579), ('only', 1555), ('must', 1523), ('little', 1485), ('those', 1447), ('good', 1444), ('should', 1417), ('after', 1379), ('great', 1358), ('every', 1356), ('first', 1318), ('own', 1289), ('did', 1271), ('how', 1266), ('see', 1251), ('these', 1244), ('men', 1233), ('over', 1209), ('where', 1205), ('make', 1196), ('upon', 1188), ('nor', 1181), ('never', 1177), ('much', 1167), ('time', 1166), ('said,', 1163), ('two', 1142), ('old', 1140), ('made', 1128)]\n"
     ]
    }
   ],
   "source": [
    "filtered_words = get_filtered_words(lowercase_words)\n",
    "top_40_filtered = compute_top_k(filtered_words, 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "excited-courage",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_json_file(top_40_filtered, \"sp2.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "standard-politics",
   "metadata": {},
   "source": [
    "## Subproject 3\n",
    "### Top 40 words without punctuations\n",
    "- Find top 40 words\n",
    "- Remove leading and trailing punctuation marks\n",
    "- Filter out the stopwords from the handout file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "pressing-climb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "\n",
    "def get_words_without_punctuations(lowercase_words):\n",
    "    all_punctuations = \".,:;'!?\"\n",
    "    return lowercase_words.map(lambda x: x.strip(all_punctuations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "sonic-plasma",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('not', 8664), ('you', 7262), ('have', 5258), ('one', 3959), ('no', 3888), ('man', 2610), ('more', 2404), ('like', 2378), ('out', 2322), ('up', 2194), ('now', 2106), ('men', 1860), ('good', 1839), ('mr', 1789), ('only', 1706), ('time', 1701), ('god', 1666), ('first', 1646), ('say', 1616), ('must', 1571), ('little', 1557), ('own', 1534), ('those', 1514), ('see', 1499), ('great', 1438), ('after', 1437), ('should', 1429), ('did', 1401), ('us', 1379), ('these', 1366), ('every', 1361), ('before', 1344), ('over', 1342), ('know', 1335), ('how', 1315), ('much', 1310), ('same', 1306), ('where', 1277), ('two', 1266), ('made', 1244)]\n"
     ]
    }
   ],
   "source": [
    "long_words = filtered_words.filter(lambda x: len(x) > 1)\n",
    "words_without_punctuations = get_words_without_punctuations(long_words)\n",
    "\n",
    "# filtered_words = get_filtered_words(long_words)\n",
    "top_40_without_punctuations = compute_top_k(words_without_punctuations, 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "genetic-acquisition",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_json_file(top_40_without_punctuations, \"sp3.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moved-forest",
   "metadata": {},
   "source": [
    "## Subproject 4\n",
    "### TF-IDF Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "breathing-success",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_words_for_document(document):\n",
    "    word_bag = db.read_text(document)\n",
    "    lowercase_words = get_lowercase_words(word_bag)\n",
    "    words_without_punctuations = get_words_without_punctuations(lowercase_words)\n",
    "    return get_filtered_words(words_without_punctuations)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "appropriate-pakistan",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def get_IDF(words_by_document):\n",
    "    unique_words = []\n",
    "    for words_for_single_document in words_by_document:\n",
    "        unique_words.append(words_for_single_document.distinct())\n",
    "    \n",
    "    large_bag = db.zip(*unique_words)\n",
    "    flattened_bag = large_bag.flatten()\n",
    "    frequencies = flattened_bag.frequencies()\n",
    "    idf = frequencies.map(lambda x: (x[0], math.log(8/x[1])))\n",
    "    return idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bridal-technical",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top5_TF_IDF(tf, idf):\n",
    "    tf = tf.frequencies()\n",
    "    tf_idf = tf.join(idf, lambda x: x[0], lambda x: x[0]).map(lambda x: (x[0][0], x[0][1] * x[1][1]))\n",
    "    return tf_idf.topk(5, key=1).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "suspended-student",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('martians', 330.6312051270939), ('pit', 164.27588179270703), ('martian', 160.11699870934734), ('cylinder', 131.00481712582965), ('hill', 118.52816787575064), ('soveraign', 1023.0852385064792), ('hath', 927.4309275892067), ('law', 902.4776290890487), ('common-wealth', 867.1271228804915), ('onely', 856.7299151720923), ('stephen', 1000.211381548001), ('john', 401.3322175442083), ('don’t', 363.90226979397124), ('dedalus', 332.71064666877373), ('mr', 331.3525586182436), ('alice', 345.1872959188527), ('gutenberg-tm', 116.4487263340708), ('rabbit', 62.383246250395075), ('electronic', 56.144921625355565), ('[illustration]', 45.747713916956386), ('justice', 496.2933812809208), ('yes', 456.0856026504527), ('plato', 447.7730786417247), ('evil', 313.30252561309527), ('unjust', 295.2806989185367), ('elizabeth', 804.0507294495366), ('darcy', 711.1690072545039), ('bennet', 578.0847485869944), ('jane', 526.0987100449985), ('bingley', 494.9070869198009), ('jo', 2476.6148761406844), ('meg', 1278.856548133099), ('amy', 1141.6134063822299), ('laurie', 1091.7068093819137), ('beth', 815.1410843384956), ('thy', 912.1712053009054), ('achilles', 829.6971751302544), ('hector', 750.6783965464207), ('thou', 474.11267150300256), ('trojan', 467.87434687796303)]\n"
     ]
    }
   ],
   "source": [
    "book_terms = []\n",
    "for book in booklist:\n",
    "    book_terms.append(get_words_for_document(book))\n",
    "\n",
    "IDF = get_IDF(book_terms)\n",
    "\n",
    "tf_idf = []\n",
    "for terms in book_terms:\n",
    "    tf_idf.extend(get_top5_TF_IDF(terms, IDF))\n",
    "\n",
    "print(tf_idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "south-earthquake",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_json_file(tf_idf, \"sp4.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "designed-carnival",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accompanied-divide",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
