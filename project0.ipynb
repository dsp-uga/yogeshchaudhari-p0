{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "compound-brunei",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.bag as db"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loved-instrumentation",
   "metadata": {},
   "source": [
    "Helper function that displays all the functions that can be invoked on an object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "raised-andrews",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_object_method(obj):\n",
    "    object_methods = [method_name for method_name in dir(obj)\n",
    "                  if callable(getattr(obj, method_name))]\n",
    "    print(object_methods)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "royal-louisiana",
   "metadata": {},
   "source": [
    "Takes an array of lists and filename as input and creates a json file from the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ceramic-jefferson",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def create_json_file(data, filename):\n",
    "    json_object = dict(data)\n",
    "    json_string = json.dumps(json_object)\n",
    "    open(\"output/%s\" % filename, \"w\").write(json_string)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "functional-bedroom",
   "metadata": {},
   "source": [
    "Computes the top K words from the bag of words for each of the subproject."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "alpha-final",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_top_k(words, k=40):\n",
    "    word_frequencies = words.frequencies()\n",
    "    top40_words = word_frequencies.topk(k, key=1)\n",
    "    word_counts = top40_words.compute()\n",
    "    print(word_counts)\n",
    "    return word_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "grateful-beatles",
   "metadata": {},
   "source": [
    "## Subproject 1\n",
    "### Top 40 words across all files\n",
    "- Find top 40 words\n",
    "- No need to filter out stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fancy-calvin",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "booklist = [\n",
    "    \"handout/data/pg36.txt\",\n",
    "    \"handout/data/pg3207.txt\",\n",
    "    \"handout/data/4300-0.txt\",\n",
    "    \"handout/data/pg19033.txt\",\n",
    "    \"handout/data/pg1497.txt\",\n",
    "    \"handout/data/pg42671.txt\",\n",
    "    \"handout/data/pg514.txt\",\n",
    "    \"handout/data/pg6130.txt\"\n",
    "]\n",
    "word_bag = db.read_text(booklist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "about-necessity",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lowercase_words(word_bag):\n",
    "    stripped_words = word_bag.str.strip()\n",
    "    split_words = stripped_words.str.split(\" \")\n",
    "    word_array = split_words.flatten().filter(lambda x: x!= \"\")\n",
    "    return word_array.map(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "elementary-wallet",
   "metadata": {},
   "outputs": [],
   "source": [
    "lowercase_words = get_lowercase_words(word_bag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "multiple-capitol",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 78837), ('and', 45168), ('of', 44739), ('to', 33436), ('a', 24234), ('in', 22126), ('that', 14818), ('he', 13019), ('is', 12918), ('his', 12270), ('i', 11044), ('with', 10296), ('for', 10036), ('as', 9639), ('be', 8834), ('was', 8787), ('not', 8141), ('it', 8123), ('but', 7856), ('by', 7701), ('or', 7407), ('her', 7403), ('they', 6735), ('which', 6517), ('you', 6354), ('on', 6214), ('from', 5811), ('at', 5695), ('are', 5590), ('she', 5458), ('all', 5437), ('their', 5285), ('have', 5146), ('had', 4647), ('this', 4090), ('my', 3841), ('so', 3710), ('we', 3629), ('no', 3620), ('if', 3571)]\n"
     ]
    }
   ],
   "source": [
    "top_40 = compute_top_k(lowercase_words, k=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "minimal-bulgarian",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_json_file(top_40, \"sp1.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collected-death",
   "metadata": {},
   "source": [
    "## Subproject 2\n",
    "### Top 40 filtered words\n",
    "- Find top 40 words\n",
    "- Filter out the stopwords from the handout file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "arbitrary-specification",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filtered_words(words):\n",
    "    stopwords = open(\"handout/data/stopwords.txt\", \"r\").read().split(\"\\n\")\n",
    "    return words.filter(lambda x: x not in stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "crazy-madonna",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('i', 11044), ('not', 8141), ('you', 6354), ('have', 5146), ('no', 3620), ('one', 3498), ('like', 2253), ('more', 2087), ('out', 2021), ('up', 1831), ('man', 1783), ('now', 1579), ('only', 1555), ('must', 1523), ('little', 1485), ('those', 1447), ('good', 1444), ('should', 1417), ('after', 1379), ('great', 1358), ('every', 1356), ('first', 1318), ('own', 1289), ('did', 1271), ('how', 1266), ('see', 1251), ('these', 1244), ('men', 1233), ('over', 1209), ('where', 1205), ('make', 1196), ('upon', 1188), ('nor', 1181), ('never', 1177), ('much', 1167), ('time', 1166), ('said,', 1163), ('two', 1142), ('old', 1140), ('made', 1128)]\n"
     ]
    }
   ],
   "source": [
    "filtered_words = get_filtered_words(lowercase_words)\n",
    "top_40_filtered = compute_top_k(filtered_words, 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "included-saint",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_json_file(top_40_filtered, \"sp2.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "difficult-radius",
   "metadata": {},
   "source": [
    "## Subproject 3\n",
    "### Top 40 words without punctuations\n",
    "- Find top 40 words\n",
    "- Remove leading and trailing punctuation marks\n",
    "- Filter out the stopwords from the handout file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "middle-squad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "\n",
    "def get_words_without_punctuations(lowercase_words):\n",
    "    all_punctuations = punctuation + \"—\"\n",
    "    return lowercase_words.map(lambda x: x.strip(all_punctuations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fatty-belle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('not', 8833), ('you', 7780), ('have', 5294), ('no', 4073), ('one', 4026), ('man', 2655), ('more', 2445), ('like', 2414), ('out', 2354), ('now', 2249), ('up', 2217), ('good', 1917), ('men', 1886), ('mr', 1820), ('god', 1756), ('time', 1738), ('only', 1730), ('say', 1670), ('first', 1659), ('must', 1581), ('little', 1569), ('own', 1549), ('see', 1526), ('those', 1525), ('how', 1460), ('after', 1457), ('did', 1453), ('great', 1451), ('should', 1437), ('us', 1406), ('these', 1384), ('know', 1377), ('every', 1372), ('before', 1367), ('over', 1353), ('much', 1341), ('where', 1332), ('same', 1313), ('well', 1309), ('two', 1292)]\n"
     ]
    }
   ],
   "source": [
    "words_without_punctuations = get_words_without_punctuations(lowercase_words)\n",
    "long_words = words_without_punctuations.filter(lambda x: len(x) > 1)\n",
    "filtered_words = get_filtered_words(long_words)\n",
    "top_40_without_punctuations = compute_top_k(filtered_words, 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "unnecessary-right",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_json_file(top_40_without_punctuations, \"sp3.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "constant-fluid",
   "metadata": {},
   "source": [
    "## Subproject 4\n",
    "### TF-IDF Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "independent-astronomy",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_words_for_document(document):\n",
    "    word_bag = db.read_text(document)\n",
    "    lowercase_words = get_lowercase_words(word_bag)\n",
    "    words_without_punctuations = get_words_without_punctuations(lowercase_words)\n",
    "    return get_filtered_words(words_without_punctuations)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "chronic-security",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def get_IDF(words_by_document):\n",
    "    unique_words = []\n",
    "    for words_for_single_document in words_by_document:\n",
    "        unique_words.append(words_for_single_document.distinct())\n",
    "    \n",
    "    large_bag = db.zip(*unique_words)\n",
    "    flattened_bag = large_bag.flatten()\n",
    "    frequencies = flattened_bag.frequencies()\n",
    "    idf = frequencies.map(lambda x: (x[0], math.log(8/x[1])))\n",
    "    return idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "improved-suffering",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top5_TF_IDF(tf, idf):\n",
    "    tf = tf.frequencies()\n",
    "    tf_idf = tf.join(idf, lambda x: x[0], lambda x: x[0]).map(lambda x: (x[0][0], x[0][1] * x[1][1]))\n",
    "    return tf_idf.topk(5, key=1).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "working-valentine",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('martians', 334.7900882104536), ('pit', 170.51420641774652), ('martian', 162.19644025102718), ('cylinder', 133.0842586675095), ('hill', 118.52816787575064), ('soveraign', 1033.4824462148783), ('hath', 927.4309275892067), ('law', 914.9542783391278), ('common-wealth', 898.318746005689), ('onely', 858.8093567137722), ('stephen', 1048.0385370066372), ('mr', 498.37282282260065), ('john', 405.49110062756796), ('don’t', 382.61724366908976), ('o', 358.0026773492801), ('alice', 349.3461790022124), ('gutenberg-tm', 116.4487263340708), ('rabbit', 64.4626877920749), ('electronic', 56.144921625355565), ('duchess', 43.66827237527655), ('justice', 496.2933812809208), ('plato', 450.5456673639644), ('virtue', 316.07511433533506), ('evil', 313.30252561309527), ('unjust', 295.2806989185367), ('elizabeth', 810.982201255136), ('darcy', 758.99616271314), ('bennet', 607.196930170512), ('jane', 540.6548008367573), ('mr', 535.1096233922777), ('jo', 2593.063602474755), ('meg', 1316.286495883336), ('amy', 1187.3611202991863), ('laurie', 1137.45452329887), ('beth', 860.888798255452), ('thy', 924.9219855900578), ('achilles', 869.2065644221714), ('hector', 773.5522535048989), ('jove', 501.8385587254004), ('thou', 483.8167320308418)]\n"
     ]
    }
   ],
   "source": [
    "book_terms = []\n",
    "for book in booklist:\n",
    "    book_terms.append(get_words_for_document(book))\n",
    "\n",
    "IDF = get_IDF(book_terms)\n",
    "\n",
    "tf_idf = []\n",
    "for terms in book_terms:\n",
    "    tf_idf.extend(get_top5_TF_IDF(terms, IDF))\n",
    "\n",
    "print(tf_idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "filled-aaron",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_json_file(tf_idf, \"sp4.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bridal-pharmaceutical",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
